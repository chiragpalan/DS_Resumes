# ğŸ“Š Comprehensive Comparative Study of Uplift / True Lift Modeling Approaches
*(For Standard Chartered Bank â€“ Proof of Concept)*

---

## ğŸ”‘ Common Notations

- **X**: Customer features (e.g., age, income, products, digital usage)  
- **Y**: Campaign outcome (1 = converted, 0 = not converted)  
- **T**: Treatment indicator (1 = received campaign, 0 = control)  
- **f, fâ‚, fâ‚€**: Predictive models  
- **Ãª(X)**: Propensity score = probability of treatment given X  
- **Ï„(X)**: Uplift = incremental effect of campaign  
- **mÌ‚(X)**: Baseline expected outcome without treatment  

---

## 1. Sâ€‘Learner (Single Model)

**Idea / Intuition**  
Use a single model that takes both customer features and the treatment flag as inputs.  
The model predicts outcomes for â€œtreatedâ€ and â€œuntreatedâ€ scenarios.  
Uplift is the difference between the two predictions.

**Workflow**
1. **Combine all data** (treated + control) into one dataset.  
2. **Add a treatment flag T** as an additional column.  
3. **Train one model** (e.g., Gradient Boosting, Logistic Regression) using (X, T) to predict Y.  
4. For each customer:
   - Predict probability of response if **treated** (T=1).  
   - Predict probability if **not treated** (T=0).  
5. **Compute uplift** as the difference.  
6. **Rank customers** by uplift to target top persuadables.  

---

## 2. Tâ€‘Learner (Two Models)

**Idea / Intuition**  
Train two separate models: one for customers who received the campaign, one for those who did not.  
Subtract predictions to get uplift.

**Workflow**
1. **Split the dataset** into two groups:
   - **Treatment group**: Customers who received the campaign (T=1).  
   - **Control group**: Customers who did not (T=0).  
2. **Train Model A** on the treatment group to predict Y given X.  
3. **Train Model B** on the control group.  
4. For each customer:
   - Predict probability from Model A (treated scenario).  
   - Predict probability from Model B (control scenario).  
5. **Compute uplift** = Model A â€“ Model B.  
6. **Rank and segment customers** by uplift scores for targeting.  

---

## 3. Class Transformation

**Idea / Intuition**  
Reâ€‘label the dataset to mark persuadable customers as the positive class and train a single classifier.

**Workflow**
1. **Reâ€‘label customers**:  
   - Mark as 1 if **treated & responded** OR **control & did not respond**  
   - Mark as 0 otherwise.  
2. **Train a classifier** (e.g., Logistic Regression, Random Forest) to predict this new label.  
3. The classifier learns patterns distinguishing persuadables.  
4. **Score new customers** â†’ Higher scores mean more likely to be persuadable.  
5. **Use top scorers** for the campaign.  

---

## 4. Uâ€‘Learner

**Idea / Intuition**  
Decompose the outcome into baseline + uplift signal. Uses residuals to capture treatment effect.

**Workflow**
1. **Fit baseline model mÌ‚(X)** on the full dataset to predict Y ignoring treatment.  
2. **Estimate propensity Ãª(X)** (probability customer was treated).  
3. For each record, compute a **pseudoâ€‘outcome H** = (Y â€“ mÌ‚(X)) / (T â€“ Ãª(X)).  
   - This adjusts actual outcome by expected baseline and treatment likelihood.  
4. **Train a regression model** on (X, H) to predict uplift.  
5. **Predict uplift Ï„(X)** for each customer.  
6. **Target customers** with highest Ï„(X).  

---

## 5. Xâ€‘Learner

**Idea / Intuition**  
Handles imbalanced treatment/control groups.  
Imputes counterfactual outcomes for each group, then learns uplift functions.

**Workflow**
1. **Step 1: Train Tâ€‘Learner models** fâ‚(X) for treated, fâ‚€(X) for control.  
2. **Step 2: Impute counterfactuals**:  
   - For treated customers, estimate what would have happened without treatment.  
   - For control customers, estimate what would have happened with treatment.  
3. **Step 3: Compute pseudoâ€‘treatment effects**:  
   - DÂ¹ = actual treated outcome â€“ imputed control outcome.  
   - Dâ° = imputed treated outcome â€“ actual control outcome.  
4. **Step 4: Train effect models** hâ‚(X) on treated, hâ‚€(X) on control using DÂ¹, Dâ°.  
5. **Step 5: Combine estimates** using propensity Ãª(X):  
   Ï„(X) = Ãª(X)Â·hâ‚€(X) + (1 â€“ Ãª(X))Â·hâ‚(X).  
6. **Rank customers** by Ï„(X).  

---

## 6. Râ€‘Learner

**Idea / Intuition**  
Separates treatment effect from other outcome predictors using residualization.  
Ensures double robustness (consistent if either outcome or propensity model is accurate).

**Workflow**
1. **Step 1: Estimate baseline outcome** mÌ‚(X).  
2. **Step 2: Estimate treatment propensity** Ãª(X).  
3. **Step 3: Compute residuals**:  
   - Å¶ = Y â€“ mÌ‚(X).  
   - TÌƒ = T â€“ Ãª(X).  
4. **Step 4: Fit regression** of Å¶ on TÌƒ with features X.  
   - Captures effect of treatment residual on outcome residual.  
5. **Step 5: Predict Ï„(X)** as the uplift score.  
6. **Use predictions** for targeting persuadables.  

---

## 7. Uplift Trees & Forests

**Idea / Intuition**  
Adapts decision tree algorithms so that each split maximizes **uplift difference** between treated and control groups.

**Workflow**
1. **Initialize a decision tree** with all customer data.  
2. **Choose splits** that maximize difference in response rates between treated and control subsets.  
3. **Grow tree** until a stopping criterion is met (e.g., min leaf size).  
4. Each **leaf node** predicts uplift = (treated response â€“ control response).  
5. **Random Forests**: build multiple uplift trees and average predictions for stability.  
6. **Interpret the rules**: e.g., â€œYoung digitalâ€‘savvy women â†’ +5pp uplift.â€  

---

## 8. Causal Forests

**Idea / Intuition**  
An ensemble of uplift trees with causal regularization, optimized for heterogeneous treatment effect estimation.

**Workflow**
1. **Build many uplift trees**, each trained on a bootstrapped sample.  
2. Use **honest splitting** (separating training of structure and treatment effect) to avoid bias.  
3. Aggregate uplift predictions across trees for each customer.  
4. Report **confidence intervals** for Ï„(X) to quantify uncertainty.  
5. **Target highâ€‘uplift segments** with reliable estimates.  

---
